---
layout: post
title: "AutoML Automated Machine Learning"
published: false
categories: []
---
### [What is AutoML?](https://www.ml4aad.org/automl/)
>  Machine learning (ML) success crucially relies on human machine learning experts to perform the following tasks:
> * Preprocess and clean the data.
> * Select and construct appropriate features.
> * Select an appropriate model family.
> * Optimize model hyperparameters.
> * Postprocess machine learning models.
> * Critically analyze the results obtained.

> ### AutoML systems
* [AutoWEKA](http://www.cs.ubc.ca/labs/beta/Projects/autoweka/) is an approach for the simultaneous selection of a machine learning algorithm and its hyperparameters; combined with the WEKA package it automatically yields good models for a wide variety of data sets.
* [Auto-sklearn](https://github.com/automl/auto-sklearn) is an extension of AutoWEKA using the Python library scikit-learn which is a drop-in replacement for regular scikit-learn classifiers and regressors.
* [TPOT](https://github.com/EpistasisLab/tpot) is a data-science assistant which optimizes machine learning pipelines using genetic programming.
* [H2O AutoML](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html) provides automated model selection and ensembling for the H2O machine learning and data analytics platform. [H2O AutoML now includes XGBoost GBMs](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html#xgboost) (Gradient Boosting Machines) among its set of algorithms.
* [TransmogrifAI](https://github.com/salesforce/TransmogrifAI)  is an AutoML library for building modular, reusable, strongly typed machine learning workflows on Apache Spark with minimal hand-tuning.
* [MLBoX](https://github.com/AxeldeRomblay/MLBox) is an AutoML  library with three components: preprocessing/cleaning/formatting, hyper-parameter optimization and prediction.


### Hyperparameter Optimization
Suggestion from Bergstra et al.’s [Making a science of model search](http://proceedings.mlr.press/v28/bergstra13.pdf). These include:
* [Hyperopt](https://github.com/jaberg/hyperopt), including the TPE algorithm
* Sequential Model-based Algorithm Configuration ([SMAC](http://www.cs.ubc.ca/labs/beta/Projects/SMAC/))
* [Spearmint](https://github.com/JasperSnoek/spearmint) A package to perform Bayesian optimization

[ML Freiburg](https://ml.informatik.uni-freiburg.de/) provide packages for hyperparameter optimization:
* [BOHB](https://www.ml4aad.org/automl/bohb/) – Bayesian Optimization combined with HyperBand
* [RoBO](http://www.ml4aad.org/automl/robo/) – Robust Bayesian Optimization framework
* [SMAC3](https://github.com/automl/SMAC3) – a python re-implementation of the SMAC algorithm

### [Architecture Search](https://www.ml4aad.org/automl/)
> The field of architecture search addresses the problem of finding a well-performing architecture of a **deep neural network**. For example, this includes the number of layers, number of neurons, the type of activation functions and many more design decisions
>
> Packages for architecture search and hyperoptimization for deep learning include:
> * [AutoKeras](https://github.com/keras-team/autokeras)
> * [DEvol](https://github.com/joeddav/devol) : Keras + Hyperopt: A very simple wrapper for convenient hyperparameter optimization
> * [HyperAS](https://github.com/maxpumperla/hyperas): a combination of Keras and Hyperopt
> * [Talos](https://github.com/autonomio/talos): Hyperparameter Optimization for Keras Models


### Preparing time series data
> Time series data must be transformed into a structure of samples with input and output components before it can be used to fit a supervised learning model

#### [Keras TimeseriesGenerator](https://keras.io/preprocessing/sequence/)
[TimeseriesGenerator](https://machinelearningmastery.com/how-to-use-the-timeseriesgenerator-for-time-series-forecasting-in-keras/) to automatically transform both univariate and multivariate time series data into samples, ready to train deep learning models. A model can be trained using the TimeseriesGenerator as a data generator. This can be achieved by fitting the defined model using the **[fit_generator()](https://keras.io/models/sequential/)** function.



### Reference
* [Time series analysis in Python](https://mlcourse.ai/articles/topic9-part1-time-series/)
* [How to Develop Multi-Step LSTM Time Series Forecasting Models for Power Usage](https://machinelearningmastery.com/how-to-develop-lstm-models-for-multi-step-time-series-forecasting-of-household-power-consumption/)
* [Using the latest advancements in deep learning to predict](https://towardsdatascience.com/aifortrading-2edd6fac689d)
* [How To Identify Patterns in Time Series Data](http://www.statsoft.com/textbook/time-series-analysis)
* [Time Series Anomaly Detection with LSTM and MXNet](https://www.lohika.com/time-series-anomaly-detection-with-lstm-and-mxnet/)
* [Time Series in Driverless AI](http://docs.h2o.ai/driverless-ai/latest-stable/docs/userguide/time-series.html)
